{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0035ac31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Obtaining dependency information for pymysql from https://files.pythonhosted.org/packages/e5/30/20467e39523d0cfc2b6227902d3687a16364307260c75e6a1cb4422b0c62/PyMySQL-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading PyMySQL-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.0-py3-none-any.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 20.5/44.8 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 30.7/44.8 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 41.0/44.8 kB 393.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 kB 371.3 kB/s eta 0:00:00\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b2c225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id \tfirst_name \tlast_name \thourly_pay \thire_date \tphone_number \tplace_of_work\n",
      "1\tEugene\t\tKrabs\t\t25.40\t\t2023-01-02\t08120745497\tKrusty Krab\n",
      "2\tSquidward\t\tTentacles\t\t15.00\t\t2023-01-03\t0807761543\tKrusty Krab\n",
      "3\tSpongebob\t\tSquarepants\t\t12.50\t\t2023-01-05\t08012309234\tKrusty Krab\n",
      "4\tPatrick\t\tStar\t\t12.50\t\t2023-01-05\t09012343256\tKrusty Krab\n",
      "5\tSandy\t\tCheeks\t\t17.50\t\t2023-01-07\t0901827654\tKrusty Krab\n",
      "6\tSheldon\t\tPlankton\t\t10.25\t\t2023-01-07\t09120767834\tKrusty Krab\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "\n",
    "db = pymysql.connect(host=\"localhost\", user=\"root\", password=\"password\",database=\"mydb2\", charset=\"utf8mb4\", cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "#prepare a cursor object for access using cursor() method\n",
    "cursor = db.cursor()\n",
    "\n",
    "#prepare sql query\n",
    "query = (\"SELECT * FROM employees\")\n",
    "\n",
    "#execute the query\n",
    "cursor.execute(query)\n",
    "#fetch all records from the query results\n",
    "data = cursor.fetchall()\n",
    "\n",
    "#print(data [0][])\n",
    "print(\"id \\tfirst_name \\tlast_name \\thourly_pay \\thire_date \\tphone_number \\tplace_of_work\")\n",
    "#print(\"{} {} {} {} {} {}\".format(\"id\", \"first_name\", \"last_name\", \"hourly_pay\", \"hire_date\", \"phone_number\", \"place_of_work\"))\n",
    "for employee in data:\n",
    "    id,first_name, last_name, hourly_pay, hire_date, phone_number, place_of_work = employee.values()\n",
    "    #print(\"{} {} {} {} {} {}\".format(id, first_name, last_name, hourly_pay, hire_date, phone_number, place_of_work))\n",
    "    print(str(id) + \"\\t\" + first_name + \"\\t\" +\"\\t\" + last_name + \"\\t\"+\"\\t\" + str(hourly_pay) + \"\\t\"+\"\\t\" + str(hire_date) + \"\\t\" + str(phone_number) + \"\\t\" + place_of_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9be7a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is done!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "url = \"https://jiji.ng/\"\n",
    "page = requests.get(url)\n",
    "#print(page)\n",
    "soup = bs(page.content, \"html5lib\")\n",
    "#print(soup.prettify())\n",
    "#table = soup.find(\"div\", attrs={\"class\": \"h-dflex h-flex-wrap h-mh--7 h-mb--15\"})\n",
    "#print(table.prettify())\n",
    "rows = soup.findAll(\"div\", attrs={\"class\": \"b-listing-cards__item\"})\n",
    "#print(rows[0])\n",
    "items = []\n",
    "df = pd.DataFrame(columns=[\"title\",\"price\",\"imageCount\",\"link\"])\n",
    "#print([rows[0].find(\"div\", attrs={\"class\": \"b-trending-card__title\"}).text])\n",
    "for row in rows:\n",
    "    item = {}\n",
    "    item[\"title\"] = row.find(\"div\", attrs={\"class\": \"b-trending-card__title\"}).text.replace(\"\\n        \",\"\").replace(\"\\n      \",\"\")\n",
    "    item[\"price\"] = row.find(\"div\", attrs={\"class\": \"b-trending-card__price\"}).text.replace(\"\\n        \",\"\").replace(\"\\n      \",\"\")\n",
    "    item[\"imageCount\"] = row.find(\"div\", attrs={\"class\": \"b-trending-card__counter\"}).text.replace(\"\\n        \",\"\").replace(\"\\n      \",\"\")\n",
    "    item[\"link\"] = row.a[\"href\"]\n",
    "    items.append(item)\n",
    "    df = df.append(item, ignore_index=True)\n",
    "    \n",
    "try:\n",
    "    engine = create_engine(\"mysql://root:password@localhost/mydb2\")\n",
    "    with engine.begin() as connection:\n",
    "        df.to_sql(name=\"web_scrapping_info\", con=connection, if_exists=\"append\", index=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"It is done!\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ceae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
